{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from survlimepy import SurvLimeExplainer\n",
    "from survlimepy.load_datasets import RandomSurvivalData\n",
    "import numpy as np\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.path.dirname(os.getcwd()), \"computed_weights_csv\", \"exp2\")\n",
    "file_name_min = \"exp_2_cluster_2_min.csv\"\n",
    "file_name_mean = \"exp_2_cluster_2_mean.csv\"\n",
    "file_name_max = \"exp_2_cluster_2_max.csv\"\n",
    "file_directory_min = os.path.join(data_folder, file_name_min)\n",
    "file_directory_mean = os.path.join(data_folder, file_name_mean)\n",
    "file_directory_max = os.path.join(data_folder, file_name_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for the first cluster\n",
    "n_points_1 = 1000\n",
    "true_coef_1 = [10**(-6), -0.15, 10**(-6), 10**(-6), -0.1]\n",
    "r_1 = 8\n",
    "center_1 = [4, -8, 2, 4, 2]\n",
    "prob_event_1 = 0.9\n",
    "lambda_weibull_1 = 10**(-5)\n",
    "v_weibull_1 = 2\n",
    "n_features_1 = len(true_coef_1)\n",
    "\n",
    "rsd_1 = RandomSurvivalData(\n",
    "    center=center_1,\n",
    "    radius=r_1,\n",
    "    coefficients=true_coef_1,\n",
    "    prob_event=prob_event_1,\n",
    "    lambda_weibull=lambda_weibull_1,\n",
    "    v_weibull=v_weibull_1,\n",
    "    time_cap=2000,\n",
    "    random_seed=90,\n",
    ")\n",
    "\n",
    "X_1, time_to_event_1, delta_1 = rsd_1.random_survival_data(num_points=n_points_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train test split for the first cluster\n",
    "n_train_1 = 900\n",
    "np.random.seed(90)\n",
    "all_idx_1 = np.arange(X_1.shape[0])\n",
    "idx_train_1 = np.random.choice(a=all_idx_1, size=n_train_1, replace=False)\n",
    "idx_test_1 = [i for i in all_idx_1 if i not in idx_train_1]\n",
    "X_train_1 = X_1[idx_train_1, :]\n",
    "X_test_1 = X_1[idx_test_1, :]\n",
    "time_to_event_train_1 = [time_to_event_1[i] for i in idx_train_1]\n",
    "time_to_event_test_1 = [time_to_event_1[i] for i in idx_test_1]\n",
    "delta_train_1 = [delta_1[i] for i in idx_train_1]\n",
    "delta_test_1 = [delta_1[i] for i in idx_test_1]\n",
    "z_train_1 = [(d, t) for d, t in zip(delta_train_1, time_to_event_train_1)]\n",
    "y_train_1 = np.array(z_train_1, dtype=[(\"delta\", np.bool_), (\"time_to_event\", np.float32)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00048407 -0.15269814 -0.00752167  0.00344847 -0.11431303]\n"
     ]
    }
   ],
   "source": [
    "# Fit a Cox model\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X_train_1, y_train_1)\n",
    "print(cox.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workin on individual 0 out of 100\n"
     ]
    }
   ],
   "source": [
    "# Experiment\n",
    "# SurvLime for COX\n",
    "col_names = [\"one\", \"two\", \"three\", \"four\", \"five\"]\n",
    "num_repetitions = 100\n",
    "num_samples = 1000\n",
    "total_test_1 = X_test_1.shape[0]\n",
    "true_coef_np = np.array(true_coef_1).reshape(1, -1)\n",
    "\n",
    "coeff_min_distance = []\n",
    "coeff_mean_distance = []\n",
    "coeff_max_distance = []\n",
    "i_individual = 0\n",
    "while i_individual < total_test_1:\n",
    "    print(f\"Workin on individual {i_individual} out of {total_test_1}\")\n",
    "    B_individual = np.full(shape=(num_repetitions, n_features_1), fill_value=np.nan)\n",
    "    individual = X_test_1[i_individual] \n",
    "    for i_sim in range(num_repetitions):\n",
    "        explainer_cox = SurvLimeExplainer(\n",
    "            training_features=X_train_1,\n",
    "            training_events=delta_train_1,\n",
    "            training_times=time_to_event_train_1,\n",
    "            model_output_times=cox.event_times_,\n",
    "            random_state=i_sim,\n",
    "        )\n",
    "        b_cox = explainer_cox.explain_instance(\n",
    "            data_row=individual,\n",
    "            predict_fn=cox.predict_cumulative_hazard_function,\n",
    "            num_samples=num_samples,\n",
    "            verbose=False,\n",
    "        )\n",
    "        B_individual[i_sim] = b_cox\n",
    "    dist_matrix = pairwise_distances(true_coef_np, B_individual)\n",
    "    idx_min = np.argmin(dist_matrix)\n",
    "    idx_max = np.argmax(dist_matrix)\n",
    "    b_min = B_individual[idx_min]\n",
    "    b_mean = np.mean(B_individual, axis=0)\n",
    "    b_max = B_individual[idx_max]\n",
    "    coeff_min_distance.append(b_min)\n",
    "    coeff_mean_distance.append(b_mean)\n",
    "    coeff_max_distance.append(b_max)\n",
    "\n",
    "    if i_individual % 5 == 0 or i_individual == (total_test_1 - 1):\n",
    "        coeff_min_distance_np = np.array(coeff_min_distance).reshape(-1, n_features_1)\n",
    "        coeff_mean_distance_np = np.array(coeff_mean_distance).reshape(-1, n_features_1)\n",
    "        coeff_max_distance_np = np.array(coeff_max_distance).reshape(-1, n_features_1)\n",
    "\n",
    "        df_to_save_min = pd.DataFrame(coeff_min_distance_np, columns=col_names)\n",
    "        df_to_save_mean = pd.DataFrame(coeff_mean_distance_np, columns=col_names)\n",
    "        df_to_save_max = pd.DataFrame(coeff_max_distance_np, columns=col_names)\n",
    "\n",
    "        df_load_min = pd.read_csv(file_directory_min)\n",
    "        df_load_mean = pd.read_csv(file_directory_mean)\n",
    "        df_load_max = pd.read_csv(file_directory_max)\n",
    "\n",
    "        df_min = pd.concat([df_load_min, df_to_save_min])\n",
    "        df_mean = pd.concat([df_load_mean, df_to_save_mean])\n",
    "        df_max = pd.concat([df_load_max, df_to_save_max])\n",
    "\n",
    "        df_min.to_csv(file_directory_min, columns=col_names, index=False)\n",
    "        df_mean.to_csv(file_directory_mean, columns=col_names, index=False)\n",
    "        df_max.to_csv(file_directory_max, columns=col_names, index=False)\n",
    "        coeff_min_distance = []\n",
    "        coeff_mean_distance = []\n",
    "        coeff_max_distance = []\n",
    "        print(f\"\\tSaved individual {i_individual}\")\n",
    "\n",
    "    i_individual += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3554df5-b49a-4656-ad30-c927f6564d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos.hernandez/dl/lib/python3.8/site-packages/pandas/core/frame.py:3069: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/home/carlos.hernandez/PhD/marato-derma/derma/general/ingestion/data_loader_csv.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target['time'] = (target['date'] - target['cb_examined_at']\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from derma.general.preprocessing.transformers import (TransformToNumeric, \n",
    "                                                      TransformToDatetime, \n",
    "                                                      ComputeAge,\n",
    "                                                      TransformToObject,\n",
    "                                                      KeepColumns,\n",
    "                                                      ComputeAJCC,\n",
    "                                                      LinkTumourPartToParent,\n",
    "                                                      TransformCbRegression,\n",
    "                                                      ConvertCategoriesToNaN,\n",
    "                                                      ExponentialTransformer,\n",
    "                                                      RenameLabValues,\n",
    "                                                      CustomScaler,\n",
    "                                                      CustomImputer,\n",
    "                                                      TransformNodMets)\n",
    "from derma.general.preprocessing.encoders import (OrdinalEncoder,\n",
    "                                                  GenderEncoder,\n",
    "                                                  AbsentPresentEncoder,\n",
    "                                                  LABEncoder,\n",
    "                                                  CategoricalEncoder)\n",
    "from derma.general.ingestion.data_loader_csv import SurvivalLoader\n",
    "from derma.sol.survival.notebooks import config_os as settings_file\n",
    "path = '/home/carlos.hernandez/datasets/csvs/data-surv_20220302.csv'\n",
    "X, time_xgboost, time, event = SurvivalLoader(target='os').load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca939e12-bf82-48c8-b99e-1c2d0371f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('TransformToNumeric', TransformToNumeric(**settings_file.transform_to_numeric)), \n",
    "    ('TransformToDatetime', TransformToDatetime(**settings_file.transform_to_datetime)),\n",
    "    ('TransformToObject', TransformToObject(**settings_file.transform_to_object)),\n",
    "    ('ComputeAge', ComputeAge(**settings_file.compute_age)),\n",
    "    ('tr_tm', LinkTumourPartToParent(**settings_file.link_tumour_part_to_parent)),\n",
    "    ('tr_cb', TransformCbRegression(**settings_file.transform_cb_regression)),\n",
    "    ('tr0', ConvertCategoriesToNaN(**settings_file.convert_categories_to_nan)),\n",
    "    ('tr2', GenderEncoder(**settings_file.gender_encoder)),\n",
    "    ('tr3', AbsentPresentEncoder(**settings_file.absent_present_encoder)),\n",
    "    (\"tr4\", CategoricalEncoder(**settings_file.categorical_encoder)),\n",
    "    ('tr7', LABEncoder(**settings_file.lab_encoder)),\n",
    "    ('OrdinalEncoder', OrdinalEncoder(**settings_file.ordinal_encoder)),\n",
    "    ('ComputeAJCC', ComputeAJCC(**settings_file.compute_ajcc)),\n",
    "    ('tr5', ExponentialTransformer(**settings_file.exponential_transformer)),\n",
    "#    ('TransformNodMets', TransformNodMets(**settings_file.transform_nod_mets)),\n",
    "    ('KeepColumns', KeepColumns(**settings_file.keep_cols)),\n",
    "    ('CustomImputer', CustomImputer(strategy='mean')),\n",
    "    ('CustomScaler', CustomScaler()),\n",
    "    ('RenameLabValues', RenameLabValues(**settings_file.rename_lab_values)),\n",
    "    ])\n",
    "\n",
    "target = pd.concat([time, event], axis=1)\n",
    "y = target\n",
    "def create_target(row):\n",
    "    if row['event'] == 0:\n",
    "        return -row['time']\n",
    "    return row['time'] \n",
    "\n",
    "splits = []\n",
    "labels = []\n",
    "for i in range(5):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                            test_size=0.2, random_state=i)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test,\n",
    "                                            test_size=0.5, random_state=i)\n",
    "    \n",
    "    X_train_pre = pipe.fit_transform(X_train.copy(), y_train)\n",
    "    \n",
    "    X_val_pre   = pipe.transform(X_val.copy())\n",
    "    X_test_pre  = pipe.transform(X_test.copy())\n",
    "    \n",
    "    \n",
    "    splits.append([X_train, X_val_pre, X_test_pre, X_train_pre])\n",
    "    labels.append([y_train, y_val, y_test])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c67df-3bca-4c94-9946-8ce0e03332aa",
   "metadata": {},
   "source": [
    "### From here onwards we leave XXMM behind and dive into the specifics of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cf8811-83c8-4d5b-b42a-1f5a443d5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgbse.metrics import concordance_index\n",
    "from xgbse.converters import (\n",
    "    convert_data_to_xgb_format, # <- it requires specifc format\n",
    "    convert_to_structured\n",
    ")\n",
    "\n",
    "\n",
    "# conver labels\n",
    "y_val = convert_to_structured(y_val['time'], y_val['event'])\n",
    "y_train = convert_to_structured(y_train['time'], y_train['event'])\n",
    "y_test = convert_to_structured(y_test['time'], y_test['event'])\n",
    "\n",
    "# and data\n",
    "dtrain = convert_data_to_xgb_format(X_train_pre, y_train, 'survival:aft')\n",
    "dval = convert_data_to_xgb_format(X_val_pre, y_val, 'survival:aft')\n",
    "\n",
    "# Instantiate some hyperparams\n",
    "PARAMS_XGB_AFT = {\n",
    "    'objective': 'survival:aft', # <- we could also use survival:cox\n",
    "    'eval_metric': 'aft-nloglik',\n",
    "    'aft_loss_distribution': 'normal',\n",
    "    'aft_loss_distribution_scale': 1.0,\n",
    "    'tree_method': 'hist', \n",
    "    'learning_rate': 5e-2, \n",
    "    'max_depth': 8, \n",
    "    'booster':'dart',\n",
    "    'subsample':0.5,\n",
    "    'min_child_weight': 50,\n",
    "    'colsample_bynode':0.5\n",
    "}\n",
    "\n",
    "\n",
    "bst = xgb.train(\n",
    "        PARAMS_XGB_AFT,\n",
    "        dtrain,\n",
    "        num_boost_round=200,\n",
    "        early_stopping_rounds=10,\n",
    "        evals=[(dval, 'val')],\n",
    "        verbose_eval=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1650535-3132-4b5d-b97b-da07d1134432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray we got 0.826 of concordance index\n"
     ]
    }
   ],
   "source": [
    "dval = convert_data_to_xgb_format(X_val_pre, y_val, 'survival:aft')\n",
    "dtest = convert_data_to_xgb_format(X_test_pre, y_test, 'survival:aft')\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "c_index = concordance_index(y_test, -preds, risk_strategy='precomputed')\n",
    "print(f'Hooray we got {round(c_index,3)} of concordance index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64442688-58fd-4534-9eb6-df3b9dc1b130",
   "metadata": {},
   "source": [
    "### Now its SurvTIME! (hehe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9c85c-d716-4ed6-9cf6-2bcb44a3fdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

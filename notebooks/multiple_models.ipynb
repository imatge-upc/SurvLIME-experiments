{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from survlimepy import SurvLimeExplainer\n",
    "from survlimepy.load_datasets import RandomSurvivalData\n",
    "from xgbse import XGBSEKaplanNeighbors\n",
    "import pandas as pd\n",
    "from pycox.models import DeepHitSingle, CoxPH\n",
    "import torchtuples as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "n_points = 500\n",
    "true_coef = [1, 1]\n",
    "r = 1\n",
    "center = [0, 0]\n",
    "prob_event = 0.9\n",
    "lambda_weibull = 10**(-6)\n",
    "v_weibull = 2\n",
    "n_features = len(true_coef)\n",
    "\n",
    "rsd = RandomSurvivalData(\n",
    "    center=center,\n",
    "    radius=r,\n",
    "    coefficients=true_coef,\n",
    "    prob_event=prob_event,\n",
    "    lambda_weibull=lambda_weibull,\n",
    "    v_weibull=v_weibull,\n",
    "    time_cap=None,\n",
    "    random_seed=90,\n",
    ")\n",
    "\n",
    "# Train\n",
    "X, time_to_event, delta = rsd.random_survival_data(num_points=n_points)\n",
    "z = [(d, t) for d, t in zip(delta, time_to_event)]\n",
    "y = np.array(z, dtype=[(\"delta\", np.bool_), (\"time_to_event\", np.float32)])\n",
    "total_row_train = X.shape[0]\n",
    "print('total_row_train:', total_row_train)\n",
    "unique_times = np.sort(np.unique(time_to_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to explain\n",
    "x_new = np.array([0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Cox model\n",
    "cox = CoxPHSurvivalAnalysis()\n",
    "cox.fit(X, y)\n",
    "print(cox.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SurvLime for COX\n",
    "explainer_cox = SurvLimeExplainer(\n",
    "    training_features=X,\n",
    "    training_events=[tp[0] for tp in y],\n",
    "    training_times=[tp[1] for tp in y],\n",
    "    model_output_times=cox.event_times_,\n",
    "    sample_around_instance=True,\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "b_cox = explainer_cox.explain_instance(\n",
    "    data_row=x_new,\n",
    "    predict_fn=cox.predict_cumulative_hazard_function,\n",
    "    num_samples=100,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "explainer_cox.plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Survival Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf = RandomSurvivalForest().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SurvLime for RSF\n",
    "explainer_rsf = SurvLimeExplainer(\n",
    "    training_features=X,\n",
    "    training_events=[tp[0] for tp in y],\n",
    "    training_times=[tp[1] for tp in y],\n",
    "    model_output_times=rsf.event_times_,\n",
    "    sample_around_instance=True,\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "b_rsf = explainer_rsf.explain_instance(\n",
    "    data_row=x_new,\n",
    "    predict_fn=rsf.predict_cumulative_hazard_function,\n",
    "    num_samples=1000,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "explainer_rsf.plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgbse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data in order to have the xgbse format\n",
    "X_df = pd.DataFrame(X, columns = ['A', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbse = XGBSEKaplanNeighbors(n_neighbors=50)\n",
    "xgbse.fit(X_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_xgbse = SurvLimeExplainer(\n",
    "    training_features=X_df,\n",
    "    training_events=[tp[0] for tp in y],\n",
    "    training_times=[tp[1] for tp in y],\n",
    "    model_output_times=xgbse.time_bins,\n",
    "    sample_around_instance=True,\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "b_xgbse = explainer_xgbse.explain_instance(\n",
    "    data_row=x_new,\n",
    "    predict_fn=xgbse.predict,\n",
    "    num_samples=1000,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "explainer_xgbse.plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepHit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data in order to have the DeepHit format\n",
    "X_transformed = X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the net\n",
    "in_features = X.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "output_bias = False\n",
    "batch_size = 256\n",
    "epochs = 512\n",
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "verbose = True\n",
    "num_durations = 50\n",
    "labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "y_transformed = labtrans.fit_transform(time_to_event[:, 0], delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_deep_hit = tt.practical.MLPVanilla(\n",
    "    in_features,\n",
    "    num_nodes,\n",
    "    labtrans.out_features,\n",
    "    batch_norm,\n",
    "    dropout,\n",
    "    output_bias=output_bias\n",
    ")\n",
    "deep_hit = DeepHitSingle(net_deep_hit, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts)\n",
    "deep_hit.optimizer.set_lr(0.001)\n",
    "\n",
    "# Train\n",
    "log = deep_hit.fit(\n",
    "    input=X_transformed,\n",
    "    target=y_transformed,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_deephit = SurvLimeExplainer(\n",
    "    training_features=X_transformed,\n",
    "    training_events=[tp[0] for tp in y],\n",
    "    training_times=[tp[1] for tp in y],\n",
    "    model_output_times=deep_hit.duration_index,\n",
    "    sample_around_instance=True,\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "# Note that we use type_fn = \"survival\" since predict_fn is survival.\n",
    "# Althought we use \"survival\", internally we transform everything to work with the cumulative hazard function.\n",
    "# Therefore, the results must be interpret in the same way as if we were passing the cumulative hazard function.\n",
    "b_deephit = explainer_deephit.explain_instance(\n",
    "    data_row=x_new,\n",
    "    predict_fn=deep_hit.predict_surv,\n",
    "    type_fn = \"survival\",\n",
    "    num_samples=1000,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "explainer_deephit.plot_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSurv\n",
    "A per when this notebook is created, the version of `pycox` is 0.2.3. For DeepSuv model, the `predict_surv` return a mtriz of size $n \\times m$, where $n$ is the number of individuals and $m$ is the number of unique times.\n",
    "\n",
    "However, the function `predict_cumulative_hazards` returns a data frame of size $m \\times n$. Therefore, if we want to use this function, we have to create a wrapper to transpose the output, since `SurvLIMEpy` needs the individuals in the rows. In this notebook, we show how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(data={'duration': time_to_event[:, 0], 'event': delta})\n",
    "y_deepsurv = get_target(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_deep_surv = tt.practical.MLPVanilla(in_features, num_nodes, 1, batch_norm,dropout, output_bias=output_bias)\n",
    "deep_surv = CoxPH(net_deep_surv, tt.optim.Adam())\n",
    "deep_surv.optimizer.set_lr(0.001)\n",
    "log = deep_surv.fit(\n",
    "    input=X_transformed,\n",
    "    target=y_deepsurv,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_surv.compute_baseline_hazards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chf(fun):\n",
    "    def inner(X):\n",
    "        Y = fun(X)\n",
    "        return Y.T\n",
    "    return inner\n",
    "\n",
    "predict_chf = create_chf(deep_surv.predict_cumulative_hazards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_deepsurv = SurvLimeExplainer(\n",
    "    training_features=X_transformed,\n",
    "    training_events=[tp[0] for tp in y],\n",
    "    training_times=[tp[1] for tp in y],\n",
    "    model_output_times=unique_times,\n",
    "    sample_around_instance=True,\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "b_deepsurv = explainer_deepsurv.explain_instance(\n",
    "    data_row=x_new,\n",
    "    predict_fn=predict_chf,\n",
    "    num_samples=1000,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "explainer_deepsurv.plot_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sv_paper",
   "language": "python",
   "name": ".sv_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5125f1d6569b6fddfcceea96a1a5016994ac21200cfc124cf085e7070af32878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

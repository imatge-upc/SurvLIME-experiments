{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from survlimepy import SurvLimeExplainer\n",
    "from survlimepy.load_datasets import RandomSurvivalData\n",
    "import pandas as pd\n",
    "from pycox.models import DeepHitSingle, CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "import torchtuples as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for the first cluster\n",
    "n_points_1 = 1000\n",
    "true_coef_1 = [10**(-6), 0.1, -0.15, 10**(-6), 10**(-6)]\n",
    "r_1 = 8\n",
    "center_1 = [0, 0, 0, 0, 0]\n",
    "prob_event_1 = 0.9\n",
    "lambda_weibull_1 = 10**(-5)\n",
    "v_weibull_1 = 2\n",
    "n_features_1 = len(true_coef_1)\n",
    "\n",
    "rsd_1 = RandomSurvivalData(\n",
    "    center=center_1,\n",
    "    radius=r_1,\n",
    "    coefficients=true_coef_1,\n",
    "    prob_event=prob_event_1,\n",
    "    lambda_weibull=lambda_weibull_1,\n",
    "    v_weibull=v_weibull_1,\n",
    "    time_cap=2000,\n",
    "    random_seed=90,\n",
    ")\n",
    "\n",
    "X_1, time_to_event_1, delta_1 = rsd_1.random_survival_data(num_points=n_points_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train test split for the first cluster\n",
    "n_train_1 = 900\n",
    "np.random.seed(90)\n",
    "all_idx_1 = np.arange(X_1.shape[0])\n",
    "idx_train_1 = np.random.choice(a=all_idx_1, size=n_train_1, replace=False)\n",
    "idx_test_1 = [i for i in all_idx_1 if i not in idx_train_1]\n",
    "X_train_1 = X_1[idx_train_1, :]\n",
    "X_test_1 = X_1[idx_test_1, :]\n",
    "time_to_event_train_1 = [time_to_event_1[i] for i in idx_train_1]\n",
    "time_to_event_test_1 = [time_to_event_1[i] for i in idx_test_1]\n",
    "delta_train_1 = [delta_1[i] for i in idx_train_1]\n",
    "delta_test_1 = [delta_1[i] for i in idx_test_1]\n",
    "z_train_1 = [(d, t) for d, t in zip(delta_train_1, time_to_event_train_1)]\n",
    "y_train_1 = np.array(z_train_1, dtype=[(\"delta\", np.bool_), (\"time_to_event\", np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data in order to have the DeepHit format\n",
    "X_transformed_train = X_train_1.astype('float32')\n",
    "X_transformed_test = X_test_1.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target = lambda df: (df['duration'].values, df['event'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_train = pd.DataFrame(data={'duration': time_to_event_train_1, 'event': delta_train_1})\n",
    "y_deepsurv_train = get_target(y_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_test = pd.DataFrame(data={'duration': time_to_event_test_1, 'event': delta_test_1})\n",
    "durations_test, events_test = get_target(y_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = X_transformed_train.shape[1]\n",
    "num_nodes = [32, 32]\n",
    "batch_norm = True\n",
    "dropout = 0.1\n",
    "output_bias = False\n",
    "batch_size = 256\n",
    "epochs = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_deep_surv = tt.practical.MLPVanilla(in_features, num_nodes, 1, batch_norm,dropout, output_bias=output_bias)\n",
    "deep_surv = CoxPH(net_deep_surv, tt.optim.Adam())\n",
    "deep_surv.optimizer.set_lr(0.001)\n",
    "log = deep_surv.fit(\n",
    "    input=X_transformed_train,\n",
    "    target=y_deepsurv_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_surv.compute_baseline_hazards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = deep_surv.predict_surv_df(X_transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = EvalSurv(predictions, durations_test, events_test, censor_surv='km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.concordance_td()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chf(fun):\n",
    "    def inner(X):\n",
    "        Y = fun(X)\n",
    "        return Y.T\n",
    "    return inner\n",
    "\n",
    "predict_chf = create_chf(deep_surv.predict_cumulative_hazards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_deepsurv = SurvLimeExplainer(\n",
    "    training_features=X_transformed_test,\n",
    "    training_events=delta_test_1,\n",
    "    training_times=time_to_event_test_1,\n",
    "    model_output_times=np.sort(np.unique(time_to_event_train_1)),\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "b_deepsurv = explainer_deepsurv.explain_instance(\n",
    "    data_row=X_test_1[0],\n",
    "    predict_fn=predict_chf,\n",
    "    num_samples=1000,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "explainer_deepsurv.plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_coef_1 = [10**(-6), 0.1, -0.15, 10**(-6), 10**(-6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_deepsurv = SurvLimeExplainer(\n",
    "    training_features=X_transformed_test,\n",
    "    training_events=delta_test_1,\n",
    "    training_times=time_to_event_test_1,\n",
    "    model_output_times=np.sort(np.unique(time_to_event_train_1)),\n",
    "    random_state=10,\n",
    ")\n",
    "\n",
    "b_deepsurv = explainer_deepsurv.montecarlo_explanation(\n",
    "    data=X_test_1[:10],\n",
    "    predict_fn=predict_chf,\n",
    "    num_samples=1000,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_deepsurv.plot_montecarlo_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_deepsurv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sv_paper",
   "language": "python",
   "name": ".sv_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
